{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ahead-insured",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"><a title=\"Data Science-AIMS-Cmr-2021-22\">Polynomial Regression (Practicals) </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-asset",
   "metadata": {},
   "source": [
    "Materials adapted from Tomi Mester on **Polynomial Regression in Python using scikit-learn (with a practical example)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('slides/slides_001.png' , width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-vanilla",
   "metadata": {},
   "source": [
    "## ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('slides/slides_002.png' , width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-jewelry",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-trouble",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to show you how to implement Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-roulette",
   "metadata": {},
   "source": [
    "Bad news: you can‚Äôt just linear regression your way through every dataset. üòî\n",
    "\n",
    "Oftentimes you‚Äôll encounter data where the relationship between the feature(s) and the response variable can‚Äôt be best described with a straight line.\n",
    "\n",
    "Just like here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('img/polReg1.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-basketball",
   "metadata": {},
   "source": [
    "See the problem? Of course we could fit a straight line to the data, but just by looking at the scatterplot we get the feeling that this time a linear line won‚Äôt cut it.\n",
    "\n",
    "If you think that the line should somehow be curved to better fit the data, then you intuitively understand why we use polynomial regression: it gives us the curvature we need so we can have more precise predictions based on our data.\n",
    "\n",
    "But let‚Äôs hold our horses just yet. üê¥\n",
    "\n",
    "Why is it called a ‚Äúpolynomial‚Äù?\n",
    "\n",
    "That‚Äôs what we‚Äôll discover in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-fiber",
   "metadata": {},
   "source": [
    "## What is a polynomial? The most important definitions you need to know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-dealing",
   "metadata": {},
   "source": [
    "Let‚Äôs break it down:\n",
    "* `poly` means ‚Äúmany‚Äù,\n",
    "* `nomial` means ‚Äúterms‚Äù (or ‚Äúparts‚Äù or ‚Äúnames‚Äù).\n",
    "\n",
    "Here‚Äôs an example of a polynomial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-scope",
   "metadata": {},
   "source": [
    "$$4x + 7$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-stand",
   "metadata": {},
   "source": [
    "Let's build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.arange(0, 30)\n",
    "output = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70,\n",
    "          75, 88, 81, 87, 95, 100, 108, 135, 151, 160, 169, 179]\n",
    "\n",
    "df = pd.DataFrame(feature )\n",
    "df.columns=['feature']\n",
    "df['output'] = output\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(feature, output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-policy",
   "metadata": {},
   "source": [
    "Now, let‚Äôs say that you‚Äôve got a hunch that the relationship between the features and the responses is non-linear, and you‚Äôd like to fit a curved line to the data.\n",
    "\n",
    "Since we have only one feature, the following polynomial regression formula applies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-profile",
   "metadata": {},
   "source": [
    "$$y = \\beta_{0} +  + \\beta_{1}x + \\beta_{2}x^{2} + \\dots +\\beta_{n}x^{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-ordinance",
   "metadata": {},
   "source": [
    "In this equation the number of coefficients $\\beta$'s is determined by the feature‚Äôs highest power (aka the degree of our polynomial; not considering $\\beta_0$, because it‚Äôs the intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-visit",
   "metadata": {},
   "source": [
    "Two questions immediately arise:\n",
    "\n",
    "1. How do we establish the degree of our polynomial (and thus the number of √üs)?\n",
    "2. How do we create $x^{2}, x^{3}$ or $x^{n}$ when originally we have $x$ as our one and only feature?\n",
    "\n",
    "\n",
    "Fortunately, there are answers to both questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-browse",
   "metadata": {},
   "source": [
    "**Answer 1:** there are methods to determine the degree of the polynomial that gives the best results. For now, let‚Äôs just go with the assumption that our dataset can be described with a 2nd degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-yield",
   "metadata": {},
   "source": [
    "**Answer 2:** we can create the new features (x raised to increasing powers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "loaded-sending",
   "metadata": {},
   "source": [
    "## STEP #1: Determining the degree of the polynomial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-welding",
   "metadata": {},
   "source": [
    "First,  import `PolynomialFeatures`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-geology",
   "metadata": {},
   "source": [
    "Then save an instance of `PolynomialFeatures` with the following settings:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialFeatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-exhibition",
   "metadata": {},
   "source": [
    "`degree` sets the degree of our polynomial function. `degree=2` means that we want to work with a 2nd degree polynomial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-advertiser",
   "metadata": {},
   "source": [
    "$$y = \\beta_{0} +  + \\beta_{1}x + \\beta_{2}x^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-typing",
   "metadata": {},
   "source": [
    "`include_bias=False` should be set to False.  If True, it will include a bias column, the feature in which\n",
    "    all polynomial powers are zero (i.e. a column of ones - acts as an\n",
    "    intercept term in a linear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-terminology",
   "metadata": {},
   "source": [
    "Long story short: `LinearRegression()` will take care of this setting by default, so there‚Äôs no need to set `include_bias` to `True`. If it wasn‚Äôt taken care of, then `include_bias=False` would mean that we deliberately want the y intercept ($\\beta_0$) to be equal to 0 ‚Äì but we don‚Äôt want tha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-transport",
   "metadata": {},
   "source": [
    "If you print poly, you see that so far we‚Äôve just created an instance of `PolynomialFeatures`, and that‚Äôs all there‚Äôs to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-tournament",
   "metadata": {},
   "source": [
    "## STEP #2: Creating the new features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = poly.fit_transform(feature.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-meeting",
   "metadata": {},
   "source": [
    "`reshape(-1,1)` transforms our numpy array x from a 1D array to a 2D array ‚Äì this is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-teach",
   "metadata": {},
   "source": [
    "There‚Äôs only one method ‚Äì `fit_transform()` ‚Äì but in fact it‚Äôs an amalgam of two separate methods: `fit()` and transform(). `fit_transform()` is a shortcut for using both at the same time, because they‚Äôre often used together.\n",
    "\n",
    "Since we want you to understand what‚Äôs happening under the hood, I‚Äôll show them to you separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-translator",
   "metadata": {},
   "source": [
    "With `fit()` we basically just declare what feature we want to transform:\n",
    "\n",
    "`transform()` performs the actual transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-metropolitan",
   "metadata": {},
   "source": [
    "# STEP #3: Creating the polynomial regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-facing",
   "metadata": {},
   "source": [
    "Now it‚Äôs time to create our machine learning model. Of course, we need to import it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-divide",
   "metadata": {},
   "source": [
    "Hold up a minute! üòÆ Isn‚Äôt this tutorial supposed to be about polynomial regression? Why are we importing LinearRegression then?\n",
    "\n",
    "Just think back to what you‚Äôve read not so long ago: polynomial regression is a linear model, that‚Äôs why we import LinearRegression. üôÇ\n",
    "\n",
    "Let‚Äôs save an instance of LinearRegression to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_model = LinearRegression()\n",
    "poly_reg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-innocent",
   "metadata": {},
   "source": [
    "Then we fit our model to our data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_model.fit(poly_features, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-liberal",
   "metadata": {},
   "source": [
    "Fitting means that we train our model by letting it know what the feature (poly_features) and the response (y) values are. When fitting/training our model, we basically instruct it to solve for the coefficients  $\\beta_{0}$ , $\\beta_{1}$ and $\\beta_{2}$ in our polynomial function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-onion",
   "metadata": {},
   "source": [
    "$$y = \\beta_{0} +   \\beta_{1}x + \\beta_{2}x^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-grenada",
   "metadata": {},
   "source": [
    "After running the code you may think that nothing happens, but believe me, the model estimated the coefficients (important: you don‚Äôt have to save it to a variable in order for it to work!):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-mobility",
   "metadata": {},
   "source": [
    "Now that our model is properly trained, we can put it to work by instructing it to predict the responses (y_predicted) based on poly_features, and the coefficients it had estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = poly_reg_model.predict(poly_features)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-valuable",
   "metadata": {},
   "source": [
    "Let‚Äôs do some dataviz to see what our model looks like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Your first polynomial regression\", size=16)\n",
    "plt.scatter(feature,output)\n",
    "plt.plot(feature, y_predicted, c=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-colon",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "* Try fitting different degrees for the polynomial models. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-fireplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continued-sapphire",
   "metadata": {},
   "source": [
    "# Coding a polynomial regression model with multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-insider",
   "metadata": {},
   "source": [
    "Oftentimes you‚Äôll have to work with data that includes more than one feature (life is complicated, I know). Let‚Äôs simulate such a situation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x_1 = np.absolute(np.random.randn(100, 1) * 10)\n",
    "x_2 = np.absolute(np.random.randn(100, 1) * 30)\n",
    "y = 2*x_1**2 + 3*x_1 + 2 + np.random.randn(100, 1)*20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-formula",
   "metadata": {},
   "source": [
    "`np.random.seed(1)` is needed so you and I can work with the same `‚Äúrandom‚Äù` data. \n",
    "\n",
    "We create some random data with some added noise: `x_1` contains 100 values for our first feature, `x_2` holds 100 values for our second feature. Our responses (100) are saved into y, as always.\n",
    "\n",
    "Let‚Äôs plot both features, just to get a visualized understanding of the relationships between the features and the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "axes[0].scatter(x_1, y)\n",
    "axes[1].scatter(x_2, y)\n",
    "axes[0].set_title(\"x_1 plotted\")\n",
    "axes[1].set_title(\"x_2 plotted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-appreciation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "advanced-voice",
   "metadata": {},
   "source": [
    "## STEP #1: Storing the variables in a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-quantity",
   "metadata": {},
   "source": [
    "Then we create a pandas dataframe where we‚Äôll store our features and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x_1\":x_1.reshape(100,), \"x_2\":x_2.reshape(100,), \"y\":y.reshape(100,)}, index=range(0,100))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-procurement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "img = ax.scatter(df['x_1'], df['x_2'] , df['y'], cmap=plt.hot())\n",
    "\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_zlabel('x_3')\n",
    "#fig.colorbar(img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-explosion",
   "metadata": {},
   "source": [
    "Get a better visual of this graph by running the file `PolyReg_unfitted.py` from the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-jacob",
   "metadata": {},
   "source": [
    "Again, reshape(100,) is needed (100, because we have 100 rows), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-biography",
   "metadata": {},
   "source": [
    "## STEP #2: Defining the training and the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-webmaster",
   "metadata": {},
   "source": [
    "Now we turn to `scikit-learn` again:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-halifax",
   "metadata": {},
   "source": [
    "`train_test_split` helps us split our data into a training and a test dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[[\"x_1\", \"x_2\"]], df[\"y\"]\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-atlanta",
   "metadata": {},
   "source": [
    "As a digression, to gain a quick understanding on how the new features or basis functions are generated, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we have two features\n",
    "sample_data = np.arange(1,7).reshape(3,2)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False , interaction_only=True)\n",
    "\n",
    "poly_features = poly.fit_transform(sample_data)\n",
    "poly_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-southeast",
   "metadata": {},
   "source": [
    "You might want to play with `include_bias=False` , `interaction_only=True` and see the changes in your basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-swaziland",
   "metadata": {},
   "source": [
    "Coming back to our original problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-battlefield",
   "metadata": {},
   "source": [
    "Here‚Äôs a step by step explanation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-climb",
   "metadata": {},
   "source": [
    "1. `X, y = df[[\"x_1\", \"x_2\"]], df[\"y\"]`: From df, we save the x_1 and x_2 columns to X, the y column to y. At this point we have the features and the responses stored in separate variables.\n",
    "2. poly = PolynomialFeatures(degree=2, include_bias=False) and poly_features = poly.fit_transform(X): just as before, we create the new polynomial features.\n",
    "3. `train_test_split(poly_features, y, test_size=0.3, random_state=42)`: Within the train_test_split method we define all of our features (poly_features) and all of our responses (y). Then, with test_size we set what percentage of our all features (poly_features) and responses (y) we‚Äôd like to allocate for testing our model‚Äôs prediction capability. In our case, it‚Äôll be 30% (0.3), because it‚Äôs a good practice. Don‚Äôt worry if it‚Äôs not clear at first: you‚Äôll understand it in a minute.  random_state needs to receive an integer value: that way anytime you rerun train_test_split, you‚Äôll receive the same results.\n",
    "4. `X_train, X_test, y_train, y_test`: train_test_split splits our features (poly_features) and responses (y) into train and test groups ‚Äì here we just save these groups into variables. The order of the variables is very important, so don‚Äôt shuffle them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-drilling",
   "metadata": {},
   "source": [
    "## STEP #3: Creating a polynomial regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-click",
   "metadata": {},
   "source": [
    "Now let‚Äôs create and fit our model, but this time, we‚Äôll train our model only on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_model = LinearRegression()\n",
    "poly_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-graham",
   "metadata": {},
   "source": [
    "The reason for us training our model only on the training data is that later we want to see how well our model will predict responses based on feature values it hasn‚Äôt seen before.\n",
    "\n",
    "Here‚Äôs how we can test how our model performs on previously unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_y_predicted = poly_reg_model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_reg_y_predicted))\n",
    "poly_reg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-diagram",
   "metadata": {},
   "source": [
    "It may be a lot to take in, so let me elaborate on it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-temple",
   "metadata": {},
   "source": [
    "* `poly_reg_y_predicted = poly_reg_model.predict(X_test)`: We save the predicted values our model predicts based on the previously unseen feature values (X_test).\n",
    "* `from sklearn.metrics import mean_squared_error`: We import mean_squared_error ‚Äì more on why in the next bullet point.\n",
    "* `poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_reg_y_predicted))`: We take the square root of mean_squared_error to get the RMSE (root mean square error) which is a commonly used metric to evaluate a machine learning model‚Äôs performance. RMSE shows how far the values your model predicts (poly_reg_y_predicted) are from the true values (y_test), on average. Roughly speaking: the smaller the RMSE, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-allowance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "asian-bidding",
   "metadata": {},
   "source": [
    "# STEP #4: Creating a linear regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-story",
   "metadata": {},
   "source": [
    "Now let‚Äôs create a linear regression model as well, so we can compare the performance of the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train, y_train)\n",
    "lin_reg_y_predicted = lin_reg_model.predict(X_test)\n",
    "lin_reg_rmse = np.sqrt(mean_squared_error(y_test, lin_reg_y_predicted))\n",
    "lin_reg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-combine",
   "metadata": {},
   "source": [
    "As you can see, the steps are the same as in the case of our polynomial regression model. There‚Äôs one important difference, though. In the train_test_split method we use X instead of poly_features, and it‚Äôs for a good reason. X contains our two original features (x_1 and x_2), so our linear regression model takes the form of:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-style",
   "metadata": {},
   "source": [
    "$$y = \\beta_{0} +   \\beta_{1}x_1 + \\beta_{2}x_{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-desperate",
   "metadata": {},
   "source": [
    "If you print `lin_reg_model.coef_` you can see the linear regression model‚Äôs values for $\\beta_{1}$ and $\\beta_{2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-affiliate",
   "metadata": {},
   "source": [
    "You can similarly print the intercept with `lin_reg_model.intercept_`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-ultimate",
   "metadata": {},
   "source": [
    "On the other hand, `poly_features` contains new features as well, created out of $x_1$ and $x_2$, so our polynomial regression model (based on a 2nd degree polynomial with two features) looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-charge",
   "metadata": {},
   "source": [
    "$$y = \\beta_{0} +   \\beta_{1}x_1 + \\beta_{2}x_{2} + \\beta_{3}x_{1}^{2} + \\beta_{4}x_{2}^{2}+ \\beta_{5}x_1x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-holly",
   "metadata": {},
   "source": [
    "What‚Äôs more interesting is $x_1x_2$ ‚Äì when two features are multiplied by each other, it‚Äôs called an interaction term. An interaction term accounts for the fact that one variable‚Äôs value may depend on another variable‚Äôs value (more on this here). poly.fit_transform() automatically created this interaction term for us, isn‚Äôt that cool? üôÇ\n",
    "\n",
    "Accordingly, if we print `poly_reg_model.coef_`, we‚Äôll get the values for five coefficients ($\\beta_{1}$, $\\beta_{2}$, $\\beta_{3}$, $\\beta_{4}$, $\\beta_{5})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-wesley",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-japan",
   "metadata": {},
   "source": [
    "The RMSE for the polynomial regression model is `20.94` (rounded), while the RMSE for the linear regression model is `62.3` (rounded). The polynomial regression model performs almost `3 times` better than the linear regression model. That‚Äôs a spectacular difference.\n",
    "\n",
    "But you know what else is spectacular?\n",
    "\n",
    "Your freshly gained knowledge on performing polynomial regression! üòâ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-france",
   "metadata": {},
   "source": [
    "Thanks!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-easter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
